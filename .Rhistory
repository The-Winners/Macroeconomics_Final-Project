names(proxy)[2]="IS-FOMC"
names(proxy)[3]="IV4"
names(proxy)[4]="IV5"
EU[15]=proxy$IV4
names(EU)[15]="PROXY"
#First Regression
regressionbase=dynlm(EPU~Lag(EPU,1)+UNEMPLOYMENT+PROXY,data=EU)
HAC=coeftest(regressionbase, vcov. = vcovHAC(regressionbase)) #This is the code for HAC robust standard errors
ses=list(HAC[,2])
ps=list(HAC[,4])
#RIDGE REGRESSION
library(ISLR)
head(Hitters)
complete.cases(Hitters)
rows_to_sel=complete.cases(Hitters)
hit=Hitters[rows_to_sel,]
complete.cases(hit)
#hit contains only the complete records (rows), with no missing values
head(hit)
#Note that there are cathegorical vars; we need to transform them into dummies
X=model.matrix(Salary ~ .,data=hit)[,-c(1,2)]
#used to convert cathegorical vars into dummy vars
#Responde is salary, x is all the other variables
y=hit$Salary
#Ridge and Lasso are implemented in library glmnet
library(glmnet)
#With alpha = 1, Lasso penalty is in place, with alplha=0, we have Ridge regression
ridge_0=glmnet(X,y,alpha=0, lambda=0)
summary(ridge_0)
#we want to run ridge with lambda>0, so we use a grid of values for lambda
grid=10^seq(-2,10, length=100)
grid
plot(grid)
ridge_grid=glmnet(X,y,alpha=0, lambda=grid, standardize=TRUE)
#I implement ridge 100 times, each with a different value of lambda in grid
#See the coefficient estimates
coef_grid=coef(ridge_grid)
#I want to select the 100 cpefficients associated with predictor hits (the second row)
coef_grid[2,] #these is the collection of estimates for beta_1 as a function of lambda
#Pay attention! results are sorted by decreasing values of lambda. Let me sort for increasing val of lambda
100:1
beta_1_ridge=coef_grid[2,100:1]#Now sorted by increasing values of lambda
plot(beta_1_ridge,type="l", xlab=expression(lambda), ylab=expression[beta])
plot(beta_1_ridge,type="l", xlab=expression(lambda), ylab=expression[beta[2]])
beta_2_ridge=coef_grid[3,100:1]
source('C:/Users/Documenti Fede/Scuola/UniversitÃ /MSc in Economics/Statistical Modelling/R Files/lesson7.R', echo=TRUE)
plot(beta_1_ridge,type="l", xlab=expression(lambda))
plot(beta_2_ridge,type="l", xlab=expression(lambda))
cv.glmnet(X,y)
set.seed(1)
cv.glmnet(X,y)
set.seed(1)
cv.glmnet(X,y, lambda=grid)
set.seed(1)
cv.glmnet(X,y, lambda=grid, alpha=0)
cv_out=cv.glmnet(X,y, lambda=grid, alpha=0)
plot(cv_out)
#RIDGE REGRESSION
library(ISLR)
head(Hitters)
complete.cases(Hitters)
rows_to_sel=complete.cases(Hitters)
hit=Hitters[rows_to_sel,]
complete.cases(hit)
#hit contains only the complete records (rows), with no missing values
head(hit)
#Note that there are cathegorical vars; we need to transform them into dummies
X=model.matrix(Salary ~ .,data=hit)[,-c(1,2)]
#used to convert cathegorical vars into dummy vars
#Responde is salary, x is all the other variables
y=hit$Salary
#Ridge and Lasso are implemented in library glmnet
library(glmnet)
#With alpha = 1, Lasso penalty is in place, with alplha=0, we have Ridge regression
ridge_0=glmnet(X,y,alpha=0, lambda=0)
summary(ridge_0)
#we want to run ridge with lambda>0, so we use a grid of values for lambda
grid=10^seq(-2,10, length=100)
grid
plot(grid)
ridge_grid=glmnet(X,y,alpha=0, lambda=grid, standardize=TRUE)
#I implement ridge 100 times, each with a different value of lambda in grid
#See the coefficient estimates
coef_grid=coef(ridge_grid)
#I want to select the 100 cpefficients associated with predictor hits (the second row)
coef_grid[2,] #these is the collection of estimates for beta_1 as a function of lambda
#Pay attention! results are sorted by decreasing values of lambda. Let me sort for increasing val of lambda
100:1
beta_1_ridge=coef_grid[2,100:1]#Now sorted by increasing values of lambda
beta_2_ridge=coef_grid[3,100:1]
plot(beta_1_ridge,type="l", xlab=expression(lambda))
plot(beta_2_ridge,type="l", xlab=expression(lambda))
#How to choose lmbda?
#Use CV methods, specifically, k-fold cross validation to choose among models
#This is implemented in function cv.glmnet
set.seed(1)
cv_out=cv.glmnet(X,y, lambda=grid, alpha=0)
plot(cv_out)
cv.out=cv.glmnet(X,y, lambda=grid, alpha=0)
plot(cv.out)
cv.out$lambda
cv.out$lambda.min
set.seed(1)
cv.out=cv.glmnet(X,y, lambda=grid, alpha=0)
plot(cv.out)
cv.out$lambda
cv.out$lambda.min
set.seed(1)
cv.out=cv.glmnet(X,y, lambda=grid, alpha=0)
plot(cv.out)
cv.out$lambda
lambda_hat=cv.out$lambda.min
cv.out.opt=glmnet(X,y,lambda_hat, alpha=0) #alpha=0 is for ridge regression
round(cv.out.opt$beta,2)
cv.out.opt=glmnet(X,y,lambda=lambda_hat, alpha=0) #alpha=0 is for ridge regression
round(cv.out.opt$beta,2)
grid
lasso_grid=glmnet(X,y, lambda=grid, alpha=1)
coef(lasso_grid)
grid
lasso_grid=glmnet(X,y, lambda=grid, alpha=1)
coef_grid=coef(lasso_grid)
beta_1_lasso=coef_grid[2,100:1]
plot(beta_1_lasso, type="l")
plot(beta_1_lasso, type="l", col="red")
beta_1_lasso=coef_grid[2,100:1]
beta_2_lasso=coef_grid[3,100:1]
plot(beta_1_lasso, type="l", col="red")
plot(beta_2_lasso, type="l", col="blue")
lasso_grid=cv.glmnet(X,y,lambda=grid,alpha=1)
plot(lasso_grid)
lambda_hat=lasso_grid$lambda.min
lambda_hat
lasso_hat=glmnet(X,y,lambda = lambda_hat, alpha=1)
lasso_hat$beta
dbeta(1,2)
plot(dbeta(1,2))
plot(beta(1,2))
plot(rbeta(1,2))
plot(dbeta(1,2))
plot(rbeta(1,2))
plot(rbeta(x,1,2))
plot(rbeta(x,1,2))
seq(1,10,100)
seq(100,10,100)
seq(10,100,length.out=100)
x=seq(10,100,length.out=100)
plot(dbeta(x,1,2))
plot(dbeta(x,1,9))
install.packages("DynareR")
plot(dbeta(x,1,9))
library(DynareR)
library(DynareR)
install.packages("DynareR")
library(DynareR)
a=1
b=2
a%%b
b%%a
install.packages("tinytex")
install.packages(c("AER", "broom", "bslib", "callr", "car", "classInt", "cli", "dbplyr", "e1071", "flextable", "future", "hardhat", "lme4", "lobstr", "pkgload", "processx", "RcppArmadillo", "recipes", "rlang", "rsample", "sass", "stringi", "strucchange", "timetk", "tree", "XML"))
warnings()
warnings(MiKTeX)
install.packages("tinytex")
library(tinytex)
check_ins
remove.packages("tinytex", lib="~/R/win-library/4.0")
install.packages("tinytex")
install.packages("tinytex")
install.packages("tinytex")
install.packages("tinytex")
install.packages("MiKTeX")
tinytex:::is_tinytex()
tinytex::install_tinytex(TRUE)
# THE FINAL PROJECT
# Author: The Winners
# Date: 06/07/2022
# PRELIMINARY OPERATIONS
# Clear the variables
rm(list = ls())
# Set the working directory to source file location with
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# Install packages
packages <- c("tidyverse", "rsdmx", "eurostat", "tbl2xts",
"tidyquant", "BCDating", "pwt10", "dplyr",
"stargazer", "car", "forecast", "tseries",
"quantmod", "eurostat", "stargazer",
"skedastic","Metrics","mFilter", "aTSA","lmtest","xts", "prediction")
new.packages <- packages[!(packages %in% installed.packages()[, "Package"])]
if (length(new.packages)) install.packages(new.packages)
invisible(lapply(packages, library, character.only = TRUE))
# Load packages
library(quantmod)
library(eurostat)
library(FKF)
library(arfima)
#Import data
# Download inflation rates from Fred
freddata <- c("PCEPI")
for (i in 1:length(freddata)) {
getSymbols(freddata[i], src = "FRED")
}
plot(PCEPI)
#Check for NA values
nas=c(which(is.na(PCEPI)))
nas
#Check for null values
zeroes=c(which(PCEPI==0))
zeroes
#Transform PCEPI in PCE inflation rates
#which is a timeseries with monthly yoy
#inflation rates
inflationus=c()
for(i in 13:length(PCEPI)){
inflationus[i]=((as.numeric(PCEPI[i])-as.numeric(PCEPI[i-12]))/(as.numeric(PCEPI[i-12])))*100
}
plot(inflationus, type="l")
for(i in 13:length(PCEPI)){
PCEPI[i]=inflationus[i]
}
PCEPI[1:12]=NA
PCEPI=na.omit(PCEPI)
PCEPI=PCEPI["1993/2022-01-01"]
plot(PCEPI, type="l")
#Store Canada, Norway, Sweden, and UK CPI data
#Canada
canadacpi=read.csv("CanadaCPI3.csv", sep=",")
canadacpi <- canadacpi %>%
filter(Products.and.product.groups == "All-items") %>%
filter(GEO == "Canada")
time=canadacpi[,1]
cutcanadacpi=as.data.frame(canadacpi[,11])
cutcanadacpi[,2]=canadacpi[,1]
cutcanadacpi[,3]=cutcanadacpi[,2]
cutcanadacpi[,2]=cutcanadacpi[,1]
cutcanadacpi[,1]=cutcanadacpi[,3]
cutcanadacpi[,3]=NULL
names(cutcanadacpi)=c("Date","Rate")
cpican=cutcanadacpi
inflationcan=c()
for(i in 13:length(cpican$Rate)){
inflationcan[i]=((as.numeric(cpican$Rate[i])-as.numeric(cpican$Rate[(i-12)]))/(as.numeric(cpican$Rate[(i-12)])))*100
}
plot(inflationcan, type="l")
for(i in 13:length(cpican$Rate)){
cpican$Rate[i]=inflationcan[i]
}
cpican[1:12,]=NA
cpican=na.omit(cpican)
cpican=cpican[25:length(cpican$Rate),]
plot(cpican$Rate, type="l")
#Norway
norwaycpi=read.csv("Norway-CPI.csv", sep=";")
norwaydata=matrix(NA,1,2)
norwaydata=as.data.frame(norwaydata)
names(norwaydata)=c("Date","Rate")
count=1
for (i in 2:length(norwaycpi$X)){
for (s in 12:1){
norwaydata[count,2]=norwaycpi[i,2+s]
count=count+1
}
}
norwaydata$Rate=rev(norwaydata$Rate)
plot(norwaydata$Rate)
norwaydata$Date <- data.frame(time = seq(as.Date('1929-01-01'), by = 'months', length = 1116))
inflationnor=c()
for(i in 13:length(norwaydata$Rate)){
inflationnor[i]=((as.numeric(norwaydata$Rate[i])-as.numeric(norwaydata$Rate[(i-12)]))/(as.numeric(norwaydata$Rate[(i-12)])))*100
}
plot(inflationnor, type="l")
for(i in 13:length(norwaydata$Rate)){
norwaydata$Rate[i]=inflationnor[i]
}
norwaydata[1:12,]=NA
norwaydata=na.omit(norwaydata)
norwaydata=norwaydata[757:1116,]
plot(norwaydata$Date,norwaydata$Rate, type="l")
#Sweden
swedencpi=read.csv("Sweden-CPI.csv", sep=" ")
names(swedencpi)=c("Date","Rate")
swedencpi=swedencpi[73:length(swedencpi$Date),]
#UK
ukcpi=read.csv("UK-CPI.csv", sep=",")
ukcpi=ukcpi[222:length(ukcpi$Title),]
names(ukcpi)=c("Date","Rate")
#EU (from 1999 onward)
eucpi=read.csv("eu-CPI.csv", sep=",")
eucpi=eucpi[4466:4770,7:8]
eucpi=eucpi[25:length(eucpi$TIME_PERIOD),]
names(eucpi)=c("Date","Rate")
#Germany (from 1993 onward)
gercpi=read.csv("Germany-CPI.csv", sep=",")
gercpi=gercpi[,c(1,2)]
names(gercpi)=c("Date","Rate")
inflationger=c()
for(i in 13:length(gercpi$Rate)){
inflationger[i]=((as.numeric(gercpi$Rate[i])-as.numeric(gercpi$Rate[(i-12)]))/(as.numeric(gercpi$Rate[(i-12)])))*100
}
plot(inflationger, type="l")
for(i in 13:length(gercpi$Rate)){
gercpi$Rate[i]=inflationger[i]
}
gercpi[1:12,]=NA
gercpi=na.omit(gercpi)
#Add german data to eu data
# gercpi$Date=as.character(gercpi$Date)
# count=1
# for(i in 1:length(gercpi$Date)){
#   for (s in 0:11){
#     gercpi$Date[count]=paste0(gercpi$Date[count],"/",as.character(s+1),"/01")
#     count=count+1
#   }
# }
# names(eucpi)=c("Date","Rate")
# gercpi$Date2=NULL
# eucpi=data.frame(rbind(gercpi,eucpi))
#Graph with all the inflation rates
plot(cpican$Rate, type="l", col="blue", dev="svg")
lines(norwaydata$Rate, type="l", col="red")
lines(gercpi$Rate, type="l", col="green")
lines(eucpi$Rate, type="l", col="yellow")
lines(ukcpi$Rate, type="l", col="pink")
lines(swedencpi$Rate, type="l", col="grey")
lines(PCEPI)
#Divide time series in chunks for analysis
#Euro area
eupart1=data.frame(eucpi[1:228,])
eupart2=data.frame(eucpi[1:96,])
#Germany
gerpart1=data.frame(gercpi[1:300,])
gerpart2=data.frame(gercpi[1:168,])
gerpart3=data.frame(gercpi[73:300,])
#UK
ukpart1=data.frame(ukcpi[1:300,])
ukpart2=data.frame(ukcpi[1:168,])
ukpart3=data.frame(ukcpi[73:300,])
#US
uscpi=PCEPI
uspart1=data.frame(uscpi[1:300,])
uspart2=data.frame(uscpi[1:168,])
uspart3=data.frame(uscpi[73:300,])
#Canada
cancpi=cpican
canpart1=data.frame(cancpi[1:300,])
canpart2=data.frame(cancpi[1:168,])
canpart3=data.frame(cancpi[73:300,])
#Norway
norcpi=norwaydata
norpart1=data.frame(norcpi[1:300,])
norpart2=data.frame(norcpi[1:168,])
norpart3=data.frame(norcpi[73:300,])
#Sweden
swecpi=swedencpi
swepart1=data.frame(swecpi[1:300,])
swepart2=data.frame(swecpi[1:168,])
swepart3=data.frame(swecpi[73:300,])
#Functions definition
arma21ss <- function(ar1, ar2, ma1, sigma) {
Tt <- matrix(c(ar1, ar2, 1, 0), ncol = 2)
Zt <- matrix(c(1, 0), ncol = 2)
ct <- matrix(0)
dt <- matrix(0, nrow = 2)
GGt <- matrix(0)
H <- matrix(c(1, ma1), nrow = 2) * sigma
HHt <- H %*% t(H)
a0 <- c(0, 0)
P0 <- matrix(1e6, nrow = 2, ncol = 2)
return(list(a0 = a0, P0 = P0, ct = ct, dt = dt, Zt = Zt, Tt = Tt, GGt = GGt,
HHt = HHt))
}
## The objective function passed to 'optim'
objective <- function(theta, yt) {
sp <- arma21ss(theta["ar1"], theta["ar2"], theta["ma1"], theta["sigma"])
ans <- fkf(a0 = sp$a0, P0 = sp$P0, dt = sp$dt, ct = sp$ct, Tt = sp$Tt,
Zt = sp$Zt, HHt = sp$HHt, GGt = sp$GGt, yt = yt)
return(-ans$logLik)
}
kalmanfilter <- function(y){
theta <- c(ar = c(0, 0), ma1 = 0, sigma = 1)
fit <- optim(theta, objective, yt = rbind(y), hessian = TRUE)
## Confidence intervals
p <- cbind(estimate = fit$par,
lowerCI = fit$par - qnorm(0.975) * sqrt(diag(solve(fit$hessian))),
upperCI = fit$par + qnorm(0.975) * sqrt(diag(solve(fit$hessian))))## Filter the series with estimated parameter values
sp <- arma21ss(fit$par["ar1"], fit$par["ar2"], fit$par["ma1"], fit$par["sigma"])
ans <- fkf(a0 = sp$a0, P0 = sp$P0, dt = sp$dt, ct = sp$ct, Tt = sp$Tt,
Zt = sp$Zt, HHt = sp$HHt, GGt = sp$GGt, yt = rbind(y))
plot(ans, type = "acf")
sm <- fks(ans)
#plot(sm)
#lines(y,col="black", lty="dotted")
return(p)
}
#Euro area
eupart1=data.frame(eucpi[1:228,])
eupart2=data.frame(eucpi[1:96,])
#Germany
gerpart1=data.frame(gercpi[1:300,])
gerpart2=data.frame(gercpi[1:168,])
gerpart3=data.frame(gercpi[73:300,])
#UK
ukpart1=data.frame(ukcpi[1:300,])
ukpart2=data.frame(ukcpi[1:168,])
ukpart3=data.frame(ukcpi[73:300,])
#US
uscpi=PCEPI
uspart1=data.frame(uscpi[1:300,])
uspart2=data.frame(uscpi[1:168,])
uspart3=data.frame(uscpi[73:300,])
#Canada
cancpi=cpican
canpart1=data.frame(cancpi[1:300,])
canpart2=data.frame(cancpi[1:168,])
canpart3=data.frame(cancpi[73:300,])
#Norway
norcpi=norwaydata
norpart1=data.frame(norcpi[1:300,])
norpart2=data.frame(norcpi[1:168,])
norpart3=data.frame(norcpi[73:300,])
#Sweden
swecpi=swedencpi
swepart1=data.frame(swecpi[1:300,])
swepart2=data.frame(swecpi[1:168,])
swepart3=data.frame(swecpi[73:300,])
#Kalman Filters
print("EU 1999-2017")
ar.1 <- -0.18
ma.1 <- 0.37
kalmanfilter(eupart1$Rate)
print("EU 1999-2006")
ar.1 <- 0.00
ma.1 <- 0.19
kalmanfilter(eupart2$Rate)
print("Germany 1993-2017")
ar.1 <- 0.44
ma.1 <- -0.32
kalmanfilter(gerpart1$Rate)
print("Germany 1993-2006")
ar.1 <- 0.39
ma.1 <- -0.39
kalmanfilter(gerpart2$Rate)
print("Germany 1999-2017")
kalmanfilter(gerpart3$Rate)
print("UK 1993-2017")
ar.1 <- 0.47
ma.1 <- -0.41
kalmanfilter(as.numeric(ukpart1$Rate))
print("UK 1993-2006")
ar.1 <- 0.6
ma.1 <- -0.66
kalmanfilter(as.numeric(ukpart2$Rate))
print("UK 1999-2017")
ar.1 <- 0.67
ma.1 <- -0.65
kalmanfilter(as.numeric(ukpart3$Rate))
print("US 1993-2017")
ar.1 <- 0.41
ma.1 <- 0.14
kalmanfilter(as.numeric(uspart1$Rate))
print("US 1993-2006")
ar.1 <- -0.16
ma.1 <- 0.43
kalmanfilter(as.numeric(uspart2$Rate))
print("US 1999-2017")
ar.1 <- -0.06
ma.1 <- 0.36
kalmanfilter(as.numeric(uspart3$Rate))
print("Canada 1993-2017")
ar.1 <- -0.15
ma.1 <- 0.42
kalmanfilter(as.numeric(canpart1$Rate))
print("Canada 1993-2006")
ar.1 <- -0.32
ma.1 <- 0.61
kalmanfilter(as.numeric(canpart2$Rate))
print("Canada 1999-2017")
ar.1 <- -0.29
ma.1 <- 0.44
kalmanfilter(as.numeric(canpart3$Rate))
print("Norway 1993-2017")
ar.1 <- 0.21
ma.1 <- 0.22
kalmanfilter(as.numeric(norpart1$Rate))
print("Norway 1993-2006")
ar.1 <- 0.25
ma.1 <- 0.16
kalmanfilter(as.numeric(norpart2$Rate))
print("Norway 1999-2017")
ar.1 <- 0.06
ma.1 <- 0.32
kalmanfilter(as.numeric(norpart3$Rate))
print("Sweden 1993-2017")
ar.1 <- 0.56
ma.1 <- -0.13
kalmanfilter(as.numeric(swepart1$Rate))
print("Sweden 1993-2006")
ar.1 <- 0.74
ma.1 <- 0.01
kalmanfilter(as.numeric(swepart2$Rate))
print("Sweden 1999-2017")
ar.1 <- -0.03
ma.1 <- 0.03
kalmanfilter(as.numeric(swepart3$Rate))
print("Sweden")
ar.1<-0.56
ma.1<- -0.13
kalmanfilter(as.numeric(swepart1$Rate))
print("Norway")
kalmanfilter(as.numeric(norpart1$Rate))#ci sono dei NA
str(supart1)
str(uspart1)
